# Agent configuration
# For CLI and other natural language interfaces

# Provider configuration (optional, defaults to "lm_studio" if not specified)
# Supported providers: "ollama", "openai", "lm_studio"
[provider]
type = "openai"

# Ollama provider configuration
[ollama]
# Default Ollama model to use
model = "qwen3:14b"
# base_url = "http://localhost:11434"  # Optional, defaults to http://localhost:11434

# OpenAI provider configuration
[openai]
model = "gpt-4o-mini"
# api_key is optional if OPENAI_API_KEY environment variable is set (recommended)
# base_url = "https://api.openai.com/v1"  # Optional, defaults to https://api.openai.com/v1

# LM Studio provider configuration
[lm_studio]
model = ""  # Default model name
# base_url = "http://localhost:1234/v1"  # Optional, defaults to http://localhost:1234/v1
# api_key is optional (LM Studio defaults to no API key required)
# Can be set via LM_STUDIO_API_KEY environment variable if needed
